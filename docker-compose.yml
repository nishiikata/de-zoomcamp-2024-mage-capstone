services:
  magic:
    image: mageai_spark_custom:1.0.0
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env
    environment:
      USER_CODE_PATH: /home/src/${PROJECT_NAME}
      ENV: ${ENV:-prod}
      # Ref: https://developers.google.com/workspace/guides/create-credentials#create_credentials_for_a_service_account
      GOOGLE_APPLICATION_CREDENTIALS: /tmp/keys/credentials.json
    command: mage start ${PROJECT_NAME}
    ports:
      - "6789:6789"
      - "${SPARK_UI_PORT:-4040}:4040"
      - "${SPARK_UI_PORT2:-4041}:4041"
    volumes:
      - .:/home/src/
      - ${IVY2_CACHE_DIR:-./.ivy2/}:/root/.ivy2/
      # Mount custom /lib/ to make `spark_jars: ["/tmp/lib/gcs-connector-hadoop3-latest.jar"]` setting work
      - ./lib/:/tmp/lib/  # Location of extra jars for pyspark
      # Ref: https://cloud.google.com/run/docs/testing/local#docker-with-google-cloud-access
      - ${GOOGLE_APPLICATION_CREDENTIALS}:/tmp/keys/credentials.json:ro
    restart: on-failure:5
