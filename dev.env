PROJECT_NAME=platform_template

# BigQuery
# Ref: https://docs.mage.ai/integrations/databases/BigQuery#add-credentials
# Service account key file path already set to use GOOGLE_APPLICATION_CREDENTIALS

# IO Config
# Ref: https://docs.mage.ai/development/io_config
# GOOGLE_LOCATION: US # Optional
# Note: Export to BigQuery will need the location so it is actually a required field
# Example based on terraform `location = var.region`:
# GOOGLE_LOCATION="asia-southeast1"
# See https://cloud.google.com/bigquery/docs/locations for more possible location values

# GCP Secrets Management
# Ref: https://docs.mage.ai/production/deploying-to-cloud/secrets/GCP
# GOOGLE_APPLICATION_CREDENTIALS="[PATH TO YOUR USER CREDENTIALS, MOST LIKELY: ~/.config/gcloud/application_default_credentials.json]"
# GCS_BUCKET=[YOUR DEV BUCKET]
# GCLOUD_PROJECT=[YOUR PROJECT]

# Kaggle API
# Ref: https://github.com/Kaggle/kaggle-api/blob/main/docs/README.md
# KAGGLE_USERNAME=datadinosaur
# KAGGLE_KEY=xxxxxxxxxxxxxx

# Compose file optional environment variables
# ENV = [This extra configuration is unwarranted for current project. Default value left to `prod`.]
# See https://docs.mage.ai/getting-started/runtime-variable#creating-runtime-variables for example usages.
# SPARK_UI_PORT = [Alternative to port 4040 for port conflicts]
# SPARK_UI_PORT2 = [Alternative to port 4041 for port conflicts]
# IVY2_CACHE_DIR = [Cache location for pyspark bigquery connector packages.
# Can be set to `%USERPROFILE%`\.ivy2\` on a Windows machine for example.
